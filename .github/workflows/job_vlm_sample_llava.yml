name: visual_language_chat sample - LLaVA

on:
  workflow_call:
    inputs:
      model_id:
        required: true
        type: string
      model_dir:
        required: true
        type: string

env:
  l_u22_ov_link: https://storage.openvinotoolkit.org/repositories/openvino/packages/nightly/2025.1.0-17911-83c047443de/l_openvino_toolkit_ubuntu22_2025.1.0.dev20250116_x86_64.tgz

jobs:
  visual_language_chat_sample-ubuntu-llava:
    runs-on: ubuntu-22.04-16-cores
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - uses: ./.github/actions/install_openvino
        with:
          ov_link: ${{ env.l_u22_ov_link }}
      - uses: ./.github/actions/build_app
        with:
          build_target: 'visual_language_chat py_openvino_genai'
      - uses: ./.github/actions/install_python_deps
      - name: Download and convert model
        run: |
          source ./ov/setupvars.sh
          optimum-cli export openvino --model ${{ inputs.model_id }} ./${{ inputs.model_dir }}
      - name: Download images
        run: |
          wget https://llava-vl.github.io/static/images/monalisa.jpg
      - name: Run visual_language_chat C++ sample
        run: >
          source ./ov/setupvars.sh
          && ./build/samples/cpp/visual_language_chat/visual_language_chat ./${{ inputs.model_dir }} monalisa.jpg
          <<< $'Who drew this painting?\nWhen did the painter live?'
        timeout-minutes: 4
